{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed8f93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Discriminator                            [16, 1]                   --\n",
      "├─Sequential: 1-1                        [16, 1]                   --\n",
      "│    └─Conv1d: 2-1                       [16, 100, 118]            (2,100)\n",
      "│    └─ReLU: 2-2                         [16, 100, 118]            --\n",
      "│    └─Conv1d: 2-3                       [16, 100, 118]            (50,100)\n",
      "│    └─ReLU: 2-4                         [16, 100, 118]            --\n",
      "│    └─Dropout: 2-5                      [16, 100, 118]            --\n",
      "│    └─Conv1d: 2-6                       [16, 200, 118]            (100,200)\n",
      "│    └─ReLU: 2-7                         [16, 200, 118]            --\n",
      "│    └─BatchNorm1d: 2-8                  [16, 200, 118]            (400)\n",
      "│    └─Dropout: 2-9                      [16, 200, 118]            --\n",
      "│    └─Flatten: 2-10                     [16, 23600]               --\n",
      "│    └─Linear: 2-11                      [16, 100]                 (2,360,100)\n",
      "│    └─ReLU: 2-12                        [16, 100]                 --\n",
      "│    └─Dropout: 2-13                     [16, 100]                 --\n",
      "│    └─Linear: 2-14                      [16, 1]                   (101)\n",
      "==========================================================================================\n",
      "Total params: 2,513,001\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,513,001\n",
      "Total mult-adds (Units.MEGABYTES): 325.50\n",
      "==========================================================================================\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 9.08\n",
      "Params size (MB): 10.05\n",
      "Estimated Total Size (MB): 19.16\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Generator                                [16, 118, 4]              --\n",
      "├─Linear: 1-1                            [16, 15104]               498,432\n",
      "├─Sequential: 1-2                        [16, 4, 118]              --\n",
      "│    └─ResBlock: 2-1                     [16, 128, 118]            --\n",
      "│    │    └─Sequential: 3-1              [16, 128, 118]            164,096\n",
      "│    └─ResBlock: 2-2                     [16, 128, 118]            --\n",
      "│    │    └─Sequential: 3-2              [16, 128, 118]            164,096\n",
      "│    └─ResBlock: 2-3                     [16, 128, 118]            --\n",
      "│    │    └─Sequential: 3-3              [16, 128, 118]            164,096\n",
      "│    └─ResBlock: 2-4                     [16, 128, 118]            --\n",
      "│    │    └─Sequential: 3-4              [16, 128, 118]            164,096\n",
      "│    └─ResBlock: 2-5                     [16, 128, 118]            --\n",
      "│    │    └─Sequential: 3-5              [16, 128, 118]            164,096\n",
      "│    └─Conv1d: 2-6                       [16, 4, 118]              516\n",
      "│    └─BatchNorm1d: 2-7                  [16, 4, 118]              8\n",
      "==========================================================================================\n",
      "Total params: 1,319,436\n",
      "Trainable params: 1,319,436\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 1.56\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 21.39\n",
      "Params size (MB): 5.28\n",
      "Estimated Total Size (MB): 26.67\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn, optim,utils\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(random_seed=41):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    \n",
    "class NPDataset(utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.tensor(X,dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.X[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_len=44):\n",
    "        super(CNN, self).__init__()\n",
    "        self.seq_len=seq_len\n",
    "        self.model=self.cnn_model()\n",
    "        \n",
    "    def cnn_model(self,):\n",
    "        model = nn.Sequential()\n",
    "        model.append(nn.Conv1d(in_channels=4, out_channels=100, kernel_size=(5,), padding=2))\n",
    "        model.append(nn.ReLU())\n",
    "        model.append(nn.Conv1d(in_channels=100, out_channels=100, kernel_size=(5,), padding=2))\n",
    "        model.append(nn.ReLU())\n",
    "        model.append(nn.Dropout(p=0.3))\n",
    "        model.append(nn.Conv1d(in_channels=100, out_channels=200, kernel_size=(5,), padding=2))\n",
    "        model.append(nn.ReLU())\n",
    "        model.append(nn.BatchNorm1d(200))\n",
    "        model.append(nn.Dropout(p=0.3))\n",
    "        model.append(nn.Flatten())\n",
    "        model.append(nn.Linear(200*seq_len,100))\n",
    "        model.append(nn.ReLU())\n",
    "        model.append(nn.Dropout(p=0.3))\n",
    "        model.add_module(\"linear\",nn.Linear(100,1))\n",
    "        return model\n",
    "    def forward(self, x):\n",
    "        x= torch.permute(x,(0,2,1))\n",
    "        return self.model(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,dim):\n",
    "        super(ResBlock,self).__init__()\n",
    "        self.dim = dim\n",
    "        model = nn.Sequential()\n",
    "        model.append(nn.Conv1d(in_channels=self.dim, out_channels=self.dim, kernel_size=(5,), padding=2))\n",
    "        model.append(nn.ReLU())\n",
    "        model.append(nn.Conv1d(in_channels=self.dim, out_channels=self.dim, kernel_size=(5,), padding=2))\n",
    "        model.append(nn.ReLU())\n",
    "        self.model = model\n",
    " \n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return x+0.3*output\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,n_sequences=10,seq_length=26):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.seq_len = seq_length\n",
    "        self.n_sequences = n_sequences\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=4, out_channels=100, kernel_size=(5,), padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=100, out_channels=100, kernel_size=(5,), padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Conv1d(in_channels=100, out_channels=200, kernel_size=(5,), padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(200*118,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3))\n",
    "        self.model.add_module(\"linear\",nn.Linear(100,1))\n",
    "        self.init()\n",
    "    def init(self,fpath=\"/Users/john/data/models/sev_pl3_5.pt\"):\n",
    "        save_model = torch.load(fpath)\n",
    "        modules = {}\n",
    "        for name, module in save_model.model.named_modules():\n",
    "            modules[name] = module\n",
    "        for name,module in self.model.named_modules():\n",
    "            if isinstance(module,(nn.Conv1d,nn.Linear,nn.BatchNorm1d)):\n",
    "                module.weight.data.copy_(modules[name].weight.data)\n",
    "                module.weight.requires_grad=False\n",
    "                module.bias.data.copy_(modules[name].bias.data)\n",
    "                module.bias.requires_grad=False\n",
    "            if isinstance(module,nn.BatchNorm1d):\n",
    "                module.running_mean.data.copy_(modules[name].running_mean.data)\n",
    "                module.running_mean.requires_grad=False\n",
    "                module.running_var.data.copy_(modules[name].running_var.data)\n",
    "                module.running_var.requires_grad=False\n",
    "    def forward(self,x):\n",
    "        x = torch.permute(x,(0,2,1))\n",
    "        return self.model(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,input_dim, seq_len,dim=128,layers=5):\n",
    "        super(Generator,self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.dim = dim\n",
    "        self.linear = nn.Linear(input_dim,seq_len*dim)\n",
    "        self.conv = nn.Sequential()\n",
    "        for i in range(layers):\n",
    "            self.conv.append(ResBlock(dim))\n",
    "        self.conv.append(nn.Conv1d(in_channels=dim, out_channels=4, kernel_size=(1,)))\n",
    "        self.conv.append(nn.BatchNorm1d(4))\n",
    "#         self.rnn = nn.LSTM(dim,4,batch_first=True)\n",
    "#         self.ln = nn.LayerNorm(4)\n",
    "    def forward(self,x):\n",
    "        x = self.linear(x).reshape(-1,self.dim,self.seq_len)\n",
    "        x = self.conv(x).permute((0,2,1))\n",
    "#         x = torch.relu(self.rnn(x)[0])\n",
    "#         x = self.ln(x)\n",
    "        return nn.functional.softmax(x,dim=2)\n",
    "   \n",
    "\n",
    "seq_len,dim=118,100\n",
    "model = Discriminator(seq_length=seq_len)\n",
    "print(summary(model, input_size=(16, seq_len,4)))\n",
    "\n",
    "# model(torch.rand((16,seq_len, 4)))\n",
    "model = Generator(32,seq_len)\n",
    "print(summary(model, input_size=(16, 32)))\n",
    "# model(torch.rand((16,32)))\n",
    "# torch.save(model,\"gan.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280d998a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:48<00:00,  4.87s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self,target=0):\n",
    "        super(MSELoss, self).__init__()\n",
    "        self.target = target\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 计算均方误差\n",
    "        return torch.mean((x-self.target)**2)\n",
    "\n",
    "batch_size,seq_len,dim=32,118,512\n",
    "generator = Generator(128,seq_len,dim)\n",
    "discriminator =Discriminator(seq_len,dim)\n",
    "criterion = MSELoss(target=1)\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-06)\n",
    "iterations = 10\n",
    "epoch_loss=[]\n",
    "for it in tqdm.tqdm(range(iterations)):\n",
    "    generator.train()\n",
    "    fake_seed = torch.rand(batch_size,128)\n",
    "    fake_input = generator(fake_seed)\n",
    "    outputs = discriminator(fake_input)\n",
    "    loss = criterion(outputs)\n",
    "    epoch_loss.append(loss.item())\n",
    "    optimizer_g.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_g.step()\n",
    "    if (it+1) % 100 ==0:\n",
    "        loss = np.average(epoch_loss)\n",
    "        epoch_loss=[]\n",
    "        print(f\"Iterations:{it+1} Loss:{loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "060ca95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>distance</th>\n",
       "      <th>values</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTGTTTTTTTCTGGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...</td>\n",
       "      <td>73</td>\n",
       "      <td>0.382150</td>\n",
       "      <td>0.639559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CTGTTTTTTTCTGGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...</td>\n",
       "      <td>72</td>\n",
       "      <td>0.889458</td>\n",
       "      <td>1.348960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CTGTTTTTTTCTAGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...</td>\n",
       "      <td>73</td>\n",
       "      <td>1.151381</td>\n",
       "      <td>0.998149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CTGTTTTTTTCTAGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...</td>\n",
       "      <td>72</td>\n",
       "      <td>0.278828</td>\n",
       "      <td>1.101954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CTGTTTTTTTCTGGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...</td>\n",
       "      <td>73</td>\n",
       "      <td>0.464135</td>\n",
       "      <td>1.224701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CTGTTTTTTTCTAGGCTAGCGTGTGCTAGCGTCCCACGCACTATTC...</td>\n",
       "      <td>73</td>\n",
       "      <td>0.406898</td>\n",
       "      <td>1.214737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CTGTTTTTTTCTGGGCTAGCGTGTGCTAGCGTCCCACGCACTATTC...</td>\n",
       "      <td>73</td>\n",
       "      <td>0.896590</td>\n",
       "      <td>0.586801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CTGTTTTTTTCTGGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...</td>\n",
       "      <td>73</td>\n",
       "      <td>1.323221</td>\n",
       "      <td>0.683968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CTGTTTTTTTCTAGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...</td>\n",
       "      <td>73</td>\n",
       "      <td>0.916669</td>\n",
       "      <td>0.683416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CTGTTTTTTTCTAGGCTAGCATGTGCTAGCATCCCACGCACTATTC...</td>\n",
       "      <td>71</td>\n",
       "      <td>0.896507</td>\n",
       "      <td>0.715848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CTGTTTTTTTCTGGGCTAGCATGTGCTAGCGTCCCACGCACTATTC...</td>\n",
       "      <td>73</td>\n",
       "      <td>0.844561</td>\n",
       "      <td>0.993108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CTGTTTTTTTCTGGGCTAGCATGTGCTAGCATCCCACGCACTATTC...</td>\n",
       "      <td>72</td>\n",
       "      <td>1.117176</td>\n",
       "      <td>1.032610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CTGTTTTTTTCTGGGCTAGCGTGTGCTAGCGTCCCACGCACTATTC...</td>\n",
       "      <td>74</td>\n",
       "      <td>1.425035</td>\n",
       "      <td>0.536263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  seq  distance    values  \\\n",
       "0   CTGTTTTTTTCTGGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...        73  0.382150   \n",
       "1   CTGTTTTTTTCTGGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...        72  0.889458   \n",
       "2   CTGTTTTTTTCTAGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...        73  1.151381   \n",
       "3   CTGTTTTTTTCTAGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...        72  0.278828   \n",
       "4   CTGTTTTTTTCTGGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...        73  0.464135   \n",
       "5   CTGTTTTTTTCTAGGCTAGCGTGTGCTAGCGTCCCACGCACTATTC...        73  0.406898   \n",
       "6   CTGTTTTTTTCTGGGCTAGCGTGTGCTAGCGTCCCACGCACTATTC...        73  0.896590   \n",
       "7   CTGTTTTTTTCTGGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...        73  1.323221   \n",
       "8   CTGTTTTTTTCTAGGCTAGCGTGTGCTAGCATCCCACGCACTATTC...        73  0.916669   \n",
       "9   CTGTTTTTTTCTAGGCTAGCATGTGCTAGCATCCCACGCACTATTC...        71  0.896507   \n",
       "10  CTGTTTTTTTCTGGGCTAGCATGTGCTAGCGTCCCACGCACTATTC...        73  0.844561   \n",
       "11  CTGTTTTTTTCTGGGCTAGCATGTGCTAGCATCCCACGCACTATTC...        72  1.117176   \n",
       "12  CTGTTTTTTTCTGGGCTAGCGTGTGCTAGCGTCCCACGCACTATTC...        74  1.425035   \n",
       "\n",
       "        pred  \n",
       "0   0.639559  \n",
       "1   1.348960  \n",
       "2   0.998149  \n",
       "3   1.101954  \n",
       "4   1.224701  \n",
       "5   1.214737  \n",
       "6   0.586801  \n",
       "7   0.683968  \n",
       "8   0.683416  \n",
       "9   0.715848  \n",
       "10  0.993108  \n",
       "11  1.032610  \n",
       "12  0.536263  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Levenshtein\n",
    "import pandas as pd\n",
    "\n",
    "class OneHotEncoder(object):\n",
    "    \n",
    "    def __init__(self,seq_len):\n",
    "        self.seq_len=seq_len\n",
    "        self.nuc_d = {'a':[1,0,0,0],\n",
    "             'c':[0,1,0,0],\n",
    "             'g':[0,0,1,0],\n",
    "             't':[0,0,0,1],\n",
    "             'n':[0,0,0,0]}\n",
    "    \n",
    "    def __call__(self,seq):\n",
    "        seq = seq[:self.seq_len].lower()\n",
    "        return np.array([self.nuc_d[x] for x in seq])\n",
    "    \n",
    "encoder = OneHotEncoder(seq_len)\n",
    "chars = \"ACGT\"\n",
    "original_seq = 'atcccgggtgaggcatcccaccatcctcagtcacagagagacccaatctaccatcagcatcagccagtaaagattaagaaaaacttagggtgaaagaaatttcacctaacacggcgca'\n",
    "original_seq=original_seq.upper()\n",
    "fake_seed = torch.rand(64,128)\n",
    "gen_seqs = generator(fake_seed)\n",
    "# dist = torch.distributions.Categorical(gen_seqs)\n",
    "# vectors = dist.sample()\n",
    "vectors = torch.argmax(gen_seqs,dim=2)\n",
    "outputs = discriminator(gen_seqs)\n",
    "seqs,dists,preds = [], [], []\n",
    "for seq,v in zip(vectors,outputs):\n",
    "    s = \"\".join([chars[i] for i in seq])\n",
    "    d = Levenshtein.distance(original_seq, s)\n",
    "    if s not in seqs:\n",
    "        seqs.append(s)\n",
    "        dists.append(d)\n",
    "        preds.append(v.detach().numpy()[0])\n",
    "        \n",
    "sdf = pd.DataFrame(data={\"seq\":seqs,\"distance\":dists,\"values\":preds})\n",
    "x_input = torch.tensor(np.array([encoder(v) for v in sdf.seq.values]),dtype=torch.float)\n",
    "sdf[\"pred\"] = discriminator(x_input)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b3dae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
