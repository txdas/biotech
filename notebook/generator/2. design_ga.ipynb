{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa84119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow import keras\n",
    "\n",
    "def one_hot_encode(df, col='seq', seq_len=44):\n",
    "    # Dictionary returning one-hot encoding of nucleotides. \n",
    "    nuc_d = {'a':[1,0,0,0],'c':[0,1,0,0],'g':[0,0,1,0],'t':[0,0,0,1], 'n':[0,0,0,0]}\n",
    "    \n",
    "    # Creat empty matrix.\n",
    "    vectors=np.empty([len(df),seq_len,4])\n",
    "    \n",
    "    # Iterate through UTRs and one-hot encode\n",
    "    for i,seq in enumerate(df[col].str[:seq_len]): \n",
    "        seq = seq.lower()\n",
    "        lst = [nuc_d[x] for x in seq]\n",
    "        if seq_len>len(seq):\n",
    "            lst += [nuc_d['n']]*(seq_len-len(seq))\n",
    "        a = np.array(lst)\n",
    "        vectors[i] = a\n",
    "    return vectors\n",
    "\n",
    "def r2(x,y):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "    return r_value**2\n",
    "\n",
    "\n",
    "datadir=f\"/Users/john/data\"\n",
    "name,seq_len=\"pl3-1-2\",118\n",
    "original_seq = 'atcccgggtgaggcatcccaccatcctcagtcacagagagacccaatctaccatcagcatcagccagtaaagattaagaaaaacttagggtgaaagaaatttcacctaacacggcgca'\n",
    "original_seq=original_seq.upper()\n",
    "model = keras.models.load_model(f\"{datadir}/models/pl3-1-2.keras\")\n",
    "prefix,suffix = original_seq[:72],original_seq[96:]\n",
    "df = pd.read_csv(f\"{datadir}/Promter/results/{name}/{name}_final.csv\")\n",
    "df[\"seq\"]= df.seq.apply(lambda x:prefix+x+suffix)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit_transform(df.loc[:,\"score\"].values.reshape(-1,1))\n",
    "df[\"isCore\"] = df[\"seq\"].apply(lambda x: x.startswith(prefix) and x.endswith(suffix))\n",
    "df[\"core\"] =df.seq.apply(lambda x:x[72:96])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290fb9f0",
   "metadata": {},
   "source": [
    "# Genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b874cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "def vectorizeSequence(seq):\n",
    "    # the order of the letters is not arbitrary.\n",
    "    # Flip the matrix up-down and left-right for reverse compliment\n",
    "    ltrdict = {'a':[1,0,0,0],'c':[0,1,0,0],'g':[0,0,1,0],'t':[0,0,0,1], 'n':[0,0,0,0]}\n",
    "    return np.array([ltrdict[x] for x in seq])\n",
    "\n",
    "def ret_rand_nuc(idx):\n",
    "    lst = [0,1,2,3]\n",
    "    lst.remove(idx)\n",
    "    x = random.sample(lst,1)[0]\n",
    "    if x == 0:\n",
    "        return [1,0,0,0] # A\n",
    "    if x == 1:\n",
    "        return [0,1,0,0] # C\n",
    "    if x == 2:\n",
    "        return [0,0,1,0] # G\n",
    "    if x == 3:\n",
    "        return [0,0,0,1] # T\n",
    "    \n",
    "def vector_to_nuc(arr, seq_len=24):\n",
    "    seq = ''\n",
    "    for i in range(seq_len):\n",
    "        if arr[i,0] == 1:\n",
    "            seq = seq + 'A'\n",
    "        if arr[i,1] == 1:\n",
    "            seq = seq + 'C'\n",
    "        if arr[i,2] == 1:\n",
    "            seq = seq + 'G'\n",
    "        if arr[i,3] == 1:\n",
    "            seq = seq + 'T'\n",
    "    return seq\n",
    "\n",
    "def convert_and_save(sequences, predictions):\n",
    "    # Convert the one-hot encoded sequences to A, C, T, G\n",
    "    seqs = []\n",
    "    for nbr in range(len(sequences)):\n",
    "        seqs.append(vector_to_nuc(sequences[nbr]))\n",
    "    df = pd.DataFrame(data=[seqs,predictions.tolist()]).transpose()\n",
    "    df.columns = ['seq', 'prediction']\n",
    "    df.sort_values('prediction', ascending=False, inplace=True)\n",
    "    return df\n",
    "\n",
    "def make_random_sequences(nbr_sequences, length, constant='', no_uaug=False, no_stop=False):\n",
    "    # Make randomized sequences, allowing for the inclusion / exclusion of uATGs / stop codons\n",
    "    seqs = []\n",
    "    nucs = {0:'A', 1:'T', 2:'C', 3:'G'}\n",
    "    i = 0\n",
    "    while i < nbr_sequences:\n",
    "        new_seq = ''\n",
    "        for n in range(length - len(constant)):\n",
    "            new_seq = new_seq + nucs[random.randint(0,3)]\n",
    "        \n",
    "        if no_uaug == False or (no_uaug==True and 'ATG' not in new_seq):\n",
    "            if no_stop == False or (no_stop == True and ('TAG' not in new_seq and 'TGA' not in new_seq and 'TAA' not in new_seq)):\n",
    "                new_seq = new_seq + constant\n",
    "                seqs.append(new_seq)\n",
    "                i+=1\n",
    "    return seqs\n",
    "\n",
    "def simple_mutate(seq, nbr_bases=2, prob=1,seq_len=24):\n",
    "    if nbr_bases > 1 and prob > random.random():\n",
    "        nbr_bases = nbr_bases\n",
    "    else:\n",
    "        nbr_bases = 1\n",
    "    lst = list(range(seq_len))\n",
    "    poss = random.sample(lst,nbr_bases)\n",
    "    for pos in poss:\n",
    "        idx = np.argmax(seq[pos])\n",
    "        seq[pos] = ret_rand_nuc(idx)\n",
    "    return seq\n",
    "\n",
    "def check_for_uaug(seq,seq_len=24):\n",
    "    seq = vector_to_nuc(seq,seq_len)\n",
    "    return 'ATG' in seq[:seq_len]\n",
    "\n",
    "def check_for_stops(seq,seq_len=24):\n",
    "    seq = vector_to_nuc(seq)\n",
    "    if 'TAG' in seq[:seq_len] or 'TGA' in seq[:seq_len] or 'TAA' in seq[:seq_len]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def negative_selection(seq, model, scaler, target_val, no_uaug=False, no_stop=False, nbr_bases_to_mutate=1, multi_mutate_prob=1):\n",
    "    seqs = np.empty([2,54,4])\n",
    "    seqs[0] = seq.copy()\n",
    "    seqs[1] = simple_mutate(seq.copy(), nbr_bases=nbr_bases_to_mutate, prob=multi_mutate_prob)\n",
    "    \n",
    "    if no_uaug == True and check_for_uaug(seqs[1]):\n",
    "        return seqs[0]\n",
    "    if no_stop == True and check_for_stops(seqs[1]):\n",
    "        return seqs[0]\n",
    "    \n",
    "    scores = model.predict(seqs).reshape()\n",
    "    scores = scaler.inverse_transform(scores)\n",
    "    if scores[1] < scores[0]:\n",
    "        if scores[1] >= target_val:\n",
    "            return seqs[1]\n",
    "        else:\n",
    "            return seqs[0]\n",
    "    else:\n",
    "        return seqs[0]    \n",
    "\n",
    "def selection(seq, model, scaler, target_val, no_uaug=False, no_stop=False, nbr_bases_to_mutate=1, multi_mutate_prob=1):\n",
    "    seqs = np.empty([2,50,4])\n",
    "    seqs[0] = seq\n",
    "    seqs[1] = simple_mutate(seq.copy(), nbr_bases=nbr_bases_to_mutate, prob=multi_mutate_prob)\n",
    "    \n",
    "    if no_uaug == True and check_for_uaug(seqs[1]):\n",
    "        return seqs[0]\n",
    "    if no_stop == True and check_for_stops(seqs[1]):\n",
    "        return seqs[0]\n",
    "    \n",
    "    scores = model.predict(seqs).reshape(-1)\n",
    "    scores = scaler.inverse_transform(scores)\n",
    "    if scores[1] > scores[0]:\n",
    "        if scores[1] <= target_val:\n",
    "            return seqs[1]\n",
    "        else:\n",
    "            return seqs[0]\n",
    "    else:\n",
    "        return seqs[0]  \n",
    "\n",
    "def wrap_seq(seqs, seq_len):\n",
    "    ret = np.empty([len(seqs),len(prefix)+seq_len+len(suffix),4])\n",
    "    for i in range(len(seqs)):\n",
    "        for j in range(len(prefix)):\n",
    "            ret[i][j] = vectorizeSequence(prefix[j].lower())\n",
    "        for j in range(seq_len):\n",
    "            idx = len(prefix)+j\n",
    "            ret[i][idx] = seqs[i][j]\n",
    "        for j in range(len(suffix)):\n",
    "            idx = len(prefix)+seq_len+j\n",
    "            ret[i][idx] = vectorizeSequence(suffix[j].lower())\n",
    "    return ret\n",
    "    \n",
    "def selection_to_target(seq, model, scaler, target_val, no_uaug=False, no_stop=False, nbr_bases_to_mutate=1, multi_mutate_prob=1, seq_len=50, accept_range=0.1):\n",
    "    seqs = np.empty([2,seq_len,4])\n",
    "    # Save the incoming sequence before mutating\n",
    "    seqs[0] = seq.copy()\n",
    "    # The mutated sequence\n",
    "    seqs[1] = simple_mutate(seq.copy(), nbr_bases=nbr_bases_to_mutate, prob=multi_mutate_prob,seq_len=seq_len)\n",
    "    \n",
    "    # Decide whether to continue with the new sequence based on the uAUG / stop codon preference\n",
    "    if no_uaug == True and check_for_uaug(seqs[1]):\n",
    "        return seqs[0]\n",
    "    if no_stop == True and check_for_stops(seqs[1]):\n",
    "        return seqs[0]\n",
    "    \n",
    "    # Accept sequences that fall within this range. May provide more sequence diversity\n",
    "    s0, s1 = vector_to_nuc(seqs[0]),vector_to_nuc(seqs[1])\n",
    "    scores = model.predict(wrap_seq(seqs,seq_len),verbose=0).reshape(-1,1)\n",
    "    scores = scaler.inverse_transform(scores).reshape(-1)\n",
    "    if scores[0] >= target_val - accept_range and scores[0] <= target_val + accept_range:\n",
    "        return seqs[0]\n",
    "    else:\n",
    "        if abs(target_val - scores[1]) <= abs(target_val - scores[0]):\n",
    "            return seqs[1]\n",
    "        else:\n",
    "            return seqs[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ca9311",
   "metadata": {},
   "source": [
    "# Evolve new sequences to hit target MRLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dfd50e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on target_rl -6 with 5 sequences:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████████▉                                                                                        | 99/400 [00:30<01:33,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after99 loss mean 0.003731155302375555\n",
      "Working on target_rl -4 with 5 sequences:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████████▉                                                                                        | 99/400 [00:32<01:38,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after99 loss mean 0.09879522025585175\n",
      "Working on target_rl -2 with 5 sequences:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████████████                                                                                       | 100/400 [00:33<01:42,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after99 loss mean 0.5655797719955444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████                                                          | 200/400 [01:04<01:06,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after199 loss mean 0.38822731375694275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████████████████████████████████                             | 300/400 [01:42<00:40,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after299 loss mean 0.26839232444763184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:17<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after399 loss mean 0.24443097412586212\n",
      "Working on target_rl 0 with 5 sequences:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████████████                                                                                       | 100/400 [00:31<01:34,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after99 loss mean 2.887516975402832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████                                                          | 200/400 [01:02<01:04,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after199 loss mean 2.2127747535705566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████████████████████████████████                             | 300/400 [01:32<00:31,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after299 loss mean 1.8687245845794678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [02:03<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after399 loss mean 1.5693457126617432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "# Dictionary where new sequences are saved\n",
    "evolved_seqs = {}\n",
    "\n",
    "# Number of evolution iterations\n",
    "iterations = 400\n",
    "# Number of bases to mutate if the probability to 'multi-mutate' is exceeded\n",
    "nbr_bases_to_mutate = 2\n",
    "# Probability to change multiple bases in an iteration\n",
    "prob_of_multi_mutation = 0.5\n",
    "# If using the original evolution model, set seq_len to 54. That model was\n",
    "# trained on UTRs that included the first for basees of the CDS (ATGG).\n",
    "seq_len = 24\n",
    "accept_range=0.1\n",
    "# Choose target MRLs and the number of sequences to create for each\n",
    "targets = [-6, -4,-2,0]\n",
    "seqs_per_target = [5, 5,5,5]\n",
    "# Choose whether or not to allow uAUGs and / or stop codons\n",
    "no_uaug = True\n",
    "no_stop = False\n",
    "seed=42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "for target_rl, nbr_sequences in zip(targets, seqs_per_target):\n",
    "    print('Working on target_rl {} with {} sequences:'.format(target_rl, nbr_sequences))\n",
    "    df = df.sample(frac=1.0)\n",
    "    # Randomly generate starting sequences for evolving\n",
    "#     rand_seqs = make_random_sequences(nbr_sequences, seq_len, no_uaug=no_uaug, no_stop=no_stop)\n",
    "    rand_seqs= df[:nbr_sequences][\"core\"]\n",
    "    test_sequences = np.empty([len(rand_seqs), seq_len, 4])\n",
    "    i = 0\n",
    "    # One-hot encode sequences\n",
    "    for seq in rand_seqs:\n",
    "        test_sequences[i] = vectorizeSequence(seq.lower())\n",
    "        i += 1\n",
    "    # Evolve sequences\n",
    "    for generation in tqdm.tqdm(range(iterations)):\n",
    "        \n",
    "        for i in range(len(test_sequences)):\n",
    "            test_sequences[i] = selection_to_target(seq=test_sequences[i], model=model, scaler=scaler, target_val=target_rl,no_uaug=no_uaug,\n",
    "                                        no_stop=no_stop, nbr_bases_to_mutate=nbr_bases_to_mutate, multi_mutate_prob=prob_of_multi_mutation, seq_len=seq_len)         \n",
    "        if (generation + 1) %  100 == 0:\n",
    "            # Final prediction then convert to text sequence\n",
    "            predictions = model.predict(wrap_seq(test_sequences,seq_len),verbose=0).reshape(-1,1)\n",
    "            predictions = scaler.inverse_transform(predictions).reshape(-1)\n",
    "            mean = abs((predictions - target_rl).mean())\n",
    "            print(f\"after{generation} loss mean {mean}\")\n",
    "            if mean<accept_range:\n",
    "                break\n",
    "        \n",
    "    converted_df = convert_and_save(test_sequences,predictions)\n",
    "    \n",
    "    evolved_seqs[target_rl] = converted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(9,6), dpi= 80)\n",
    "for i in evolved_seqs:\n",
    "    if i:\n",
    "        sns.kdeplot(evolved_seqs[i]['prediction'], shade=True, legend=True, label=i)\n",
    "# Decoration\n",
    "plt.title('Design Sev', fontsize=22)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# evolved_seqs[8].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
