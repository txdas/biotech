{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0674e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "seq_len=118\n",
    "border_mode = 'same'\n",
    "\n",
    "class MyHyperModel(keras_tuner.HyperModel) :\n",
    "     def build(self, hp) : \n",
    "        model = keras.Sequential()\n",
    "        layers=hp.Int(\"num_conv\", min_value=1, max_value=4, step=1)\n",
    "        nodes=hp.Choice(\"neurons\", [40,80,100, 200])\n",
    "        nbr_filters=hp.Choice(\"filters\", [40,80,100, 200])\n",
    "        filter_len=hp.Choice(\"filter_len\", [4,8, 12])\n",
    "        drop_rate = hp.Float(\"drop_rate\", min_value=0, max_value=0.35, step=0.10)\n",
    "        if layers >= 1:\n",
    "            model.add(keras.layers.Conv1D(activation=\"relu\", input_shape=(seq_len, 4), padding=border_mode, filters=nbr_filters, kernel_size=filter_len))\n",
    "        if layers >= 2:\n",
    "            model.add(keras.layers.Conv1D(activation=\"relu\", input_shape=(seq_len, 1), padding=border_mode, filters=nbr_filters, kernel_size=filter_len))\n",
    "            model.add(keras.layers.Dropout(drop_rate))\n",
    "        if layers >= 3:\n",
    "            model.add(keras.layers.Conv1D(activation=\"relu\", input_shape=(seq_len, 1), padding=border_mode, filters=nbr_filters, kernel_size=filter_len))\n",
    "            model.add(keras.layers.Dropout(drop_rate))\n",
    "        model.add(keras.layers.Flatten())\n",
    "\n",
    "        model.add(keras.layers.Dense(nodes,kernel_initializer='glorot_normal',bias_initializer='zeros'))\n",
    "        model.add(keras.layers.Activation('relu'))\n",
    "        model.add(keras.layers.Dropout(drop_rate))\n",
    "\n",
    "        model.add(keras.layers.Dense(1,kernel_initializer='glorot_normal',bias_initializer='zeros'))\n",
    "        model.add(keras.layers.Activation('linear'))\n",
    "\n",
    "        #compile the model\n",
    "        learning_rate=hp.Choice('lr', [0.01, 0.005,0.001])\n",
    "        adam = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-06)\n",
    "        model.compile(loss=\"mean_squared_error\", optimizer=adam)\n",
    "        return model\n",
    "     \n",
    "     \n",
    "     def fit(self, hp, model,x, *args, **kwargs) :\n",
    "         \n",
    "         return model.fit( x, \n",
    "                          *args,\n",
    "                          shuffle=hp.Boolean(\"shuffle\"),\n",
    "                          **kwargs)\n",
    "\n",
    "hp = keras_tuner.HyperParameters()\n",
    "hypermodel = MyHyperModel()\n",
    "model = hypermodel.build(hp)\n",
    "# hypermodel.fit(hp, model, np.random.rand(BATCH_SIZE, 400, 400,3), np.random.rand(BATCH_SIZE, classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe673ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 06s]\n",
      "val_loss: 1.002669095993042\n",
      "\n",
      "Best val_loss So Far: 0.9794211387634277\n",
      "Total elapsed time: 00h 02m 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_conv': 2,\n",
       " 'neurons': 200,\n",
       " 'filters': 40,\n",
       " 'filter_len': 4,\n",
       " 'drop_rate': 0.30000000000000004,\n",
       " 'lr': 0.001,\n",
       " 'shuffle': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "def one_hot_encode(df, col='seq', seq_len=44):\n",
    "    # Dictionary returning one-hot encoding of nucleotides. \n",
    "    nuc_d = {'a':[1,0,0,0],'c':[0,1,0,0],'g':[0,0,1,0],'t':[0,0,0,1], 'n':[0,0,0,0]}\n",
    "    \n",
    "    # Creat empty matrix.\n",
    "    vectors=np.empty([len(df),seq_len,4])\n",
    "    \n",
    "    # Iterate through UTRs and one-hot encode\n",
    "    for i,seq in enumerate(df[col].str[:seq_len]): \n",
    "        seq = seq.lower()\n",
    "        lst = [nuc_d[x] for x in seq]\n",
    "        if seq_len>len(seq):\n",
    "            lst += [nuc_d['n']]*(seq_len-len(seq))\n",
    "        a = np.array(lst)\n",
    "        vectors[i] = a\n",
    "    return vectors\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "name=\"pl5-2-1\"\n",
    "datadir=f\"/Users/john/data/sev/results/{name}/{name}_\"\n",
    "# datadir=\"./data\"\n",
    "e_train = pd.read_csv(f\"{datadir}train.csv\")\n",
    "e_test= pd.read_csv(f\"{datadir}test.csv\")\n",
    "print(e_train.shape, e_test.shape)\n",
    "\n",
    "seq_e_train = one_hot_encode(e_train,seq_len=seq_len)\n",
    "seq_e_test = one_hot_encode(e_test, seq_len=seq_len)\n",
    "label = 'score' # abs_score:0.2987 0.6760\n",
    "e_test.loc[:,'scaled_rl'] = preprocessing.StandardScaler().fit_transform(e_test.loc[:,label].values.reshape(-1,1))\n",
    "e_train.loc[:,'scaled_rl'] = preprocessing.StandardScaler().fit_transform(e_train.loc[:,label].values.reshape(-1,1))\n",
    "hp = keras_tuner.HyperParameters()\n",
    "hypermodel = MyHyperModel()\n",
    "model = hypermodel.build(hp)\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "                         hypermodel=MyHyperModel(),\n",
    "                         objective = \"val_loss\",\n",
    "                         max_trials =20, #max candidates to test\n",
    "                         overwrite=True,\n",
    "                         directory='./data/keras_tuner',\n",
    "                         project_name='sev')\n",
    "tuner.search(seq_e_train, e_train['scaled_rl'], epochs=2, batch_size=32,\n",
    "              validation_data=(seq_e_test,e_test[\"scaled_rl\"]))\n",
    "tuner.get_best_hyperparameters(1)[0].values\n",
    "# best_hps = tuner.get_best_hyperparameters(1)\n",
    "#  h_model = MyHyperModel()\n",
    "#  model = h_model.build(best_hps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbccb8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
